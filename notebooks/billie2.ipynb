{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mattmastin/opt/anaconda3/envs/billie-env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/mattmastin/opt/anaconda3/envs/billie-env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/mattmastin/opt/anaconda3/envs/billie-env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/mattmastin/opt/anaconda3/envs/billie-env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/mattmastin/opt/anaconda3/envs/billie-env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/mattmastin/opt/anaconda3/envs/billie-env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "import sys\n",
    "\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './Lyrics_JSON'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregating separate JSON lyric files\n",
    "\n",
    "def gather_data(path_to_data):\n",
    "    data = []\n",
    "    \n",
    "    for f in os.listdir(path):\n",
    "        if os.path.isdir(f) == False:\n",
    "            if f[-4:] == 'json':\n",
    "                with open(os.path.join(path, f)) as t:\n",
    "                    #for lyrics in t['Lyrics']:\n",
    "                    text = t.read().strip('\\n')\n",
    "                    data.append(str(text))\n",
    "                    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics = gather_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tokenize(text):\n",
    "#     return [token for token in simple_preprocess(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('lyrics_aggregated.txt', 'w') as filehandle:\n",
    "#     filehandle.writelines('%s\\n' % line for line in lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (open('lyrics_aggregated.txt').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple pass at cleaning text\n",
    "\n",
    "# text = text.replace('\\n', '')\n",
    "text = text.replace('{', '')\n",
    "text = text.replace('}', '')\n",
    "# text = text.replace(\"\\\", '')\n",
    "text = text.replace('[', '')\n",
    "text = text.replace(']', '')\n",
    "text = text.replace('lyrics', '')\n",
    "text = text.replace('title', '')\n",
    "text = text.replace('\"', '')\n",
    "text = text.replace('genius', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating character/word mappings\n",
    "# All unique characters/words are mapped to a number\n",
    "\n",
    "characters = sorted(list(set(text)))\n",
    "chars_to_int = dict((c, i) for i, c in enumerate(characters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total characters: 46088, total vocab: 52\n"
     ]
    }
   ],
   "source": [
    "n_chars = len(text)\n",
    "n_vocab = len(characters)\n",
    "print(f'total characters: {n_chars}, total vocab: {n_vocab}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total patterns: 45988\n"
     ]
    }
   ],
   "source": [
    "# Training and target array for LSTM model\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "seq_length = 100\n",
    "\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "    sequence = text[i:i + seq_length]\n",
    "    label = text[i + seq_length]\n",
    "    X.append([chars_to_int[char] for char in sequence])\n",
    "    y.append(chars_to_int[label])\n",
    "    \n",
    "n_patterns = len(X)\n",
    "print(f'total patterns: {n_patterns}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifying array shapes for LSTM, transform y into one-hot encoded\n",
    "\n",
    "X_modified = np.reshape(X, (n_patterns, seq_length, 1))\n",
    "\n",
    "#normalize\n",
    "X_modified = X_modified / float(n_vocab)\n",
    "y_modified = np_utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential model with two LSTM layers with 400 units each\n",
    "# Dropoout layer to check for over-fitting\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X_modified.shape[1], X_modified.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y_modified.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "45988/45988 [==============================] - 431s 9ms/step - loss: 2.3489\n",
      "Epoch 2/3\n",
      "45988/45988 [==============================] - 440s 10ms/step - loss: 2.1786\n",
      "Epoch 3/3\n",
      "45988/45988 [==============================] - 459s 10ms/step - loss: 2.0702\n",
      "CPU times: user 1h 9min 50s, sys: 6min 54s, total: 1h 16min 45s\n",
      "Wall time: 22min 9s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a45311a50>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Baseline model\n",
    "\n",
    "model.fit(X_modified, y_modified, epochs=3, batch_size=128)\n",
    "\n",
    "# model.save_weights('text_generator_400_0.2_400_0.2_baseline.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_to_char = dict((i, c) for i, c in enumerate(characters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\"          nobody's stopping you, baby, from making it too,\n",
      "            one glimpse'll show you now, b\n",
      " s wevb \n",
      "e             so\n",
      "sele'g niptelnnslt,\n",
      "donisomah ,ofgk\n",
      "\n",
      "\n",
      "           sdtlyndwer t sf tn nout  mueai \n",
      "            hfe ideann a knvo,w uh,shd,mb da'fanentpta\n",
      "c  \n",
      "           a lfsabut wyn serle    t         ad atur liiobnyu,o akot  \n",
      "          i,e              ,oi bspiihtrf tt,u,mll1iaaoo jo               m a givtewt  hedn ynk i lyrn  w wdloy              ahuwwht loe ct,ia1ait,llahi c              i r sev bftelthhpihl\n",
      "\n",
      "            thatoethwk  let,kooeqss, t r ldi l yeue\n",
      "wnih              y,i'u"
     ]
    }
   ],
   "source": [
    "# Pick a random seed from text data\n",
    "\n",
    "start = np.random.randint(0, len(X) - 1)\n",
    "pattern = X[start]\n",
    "print('Seed:')\n",
    "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern])), \"\\\"\"\n",
    "\n",
    "# Generate characters\n",
    "for i in range(500):\n",
    "    x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_vocab)\n",
    "    \n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = np.random.choice(len(prediction[0]), p=prediction[0])\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    sys.stdout.write(result)\n",
    "    \n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.3925453e-02, 5.6918347e-01, 1.7135640e-03, 5.6058483e-04,\n",
       "        8.2081935e-04, 3.3069386e-03, 1.6618368e-03, 6.8595693e-03,\n",
       "        6.4842305e-03, 1.1540813e-03, 5.4565761e-03, 6.3753757e-03,\n",
       "        2.6482113e-03, 1.6103856e-03, 9.3915942e-04, 1.0843370e-03,\n",
       "        1.8812113e-03, 1.2088580e-02, 1.1178488e-03, 1.9463705e-03,\n",
       "        5.9105419e-03, 1.2871384e-02, 4.2035472e-02, 4.2130803e-03,\n",
       "        1.9000366e-02, 2.1447646e-03, 1.0639472e-03, 3.9623775e-02,\n",
       "        1.1519723e-02, 2.4152214e-03, 1.0786365e-03, 1.0191180e-02,\n",
       "        4.3848651e-03, 3.3273061e-03, 2.6339002e-02, 6.8344916e-03,\n",
       "        7.9470209e-04, 3.4503844e-02, 1.5191199e-02, 3.2295494e-03,\n",
       "        6.8122791e-03, 5.5340368e-02, 2.7372271e-03, 9.4096269e-04,\n",
       "        3.7023611e-03, 6.6317222e-04, 5.1501021e-03, 2.0916974e-03,\n",
       "        2.3952436e-03, 1.0559686e-03, 6.6319597e-04, 9.5597759e-04]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
